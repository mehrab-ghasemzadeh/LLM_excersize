{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534e494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./text.txt','r',encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67215ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9195"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = re.split(r'([,.;?_!\"()\\']|--|\\s)',text)\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d453f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words.extend(['<|EOT|>'])\n",
    "all_words = list(set(all_words))\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523bd02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe_breaker(st):\n",
    "    subsets = []\n",
    "    for i in range(len(st)):\n",
    "        for j in range(len(st)-i+1):\n",
    "            if st[i:i+j]:\n",
    "                subsets.append(st[i:i+j])\n",
    "    subsets = sorted(set(subsets), key=len, reverse=True)\n",
    "    return subsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d76f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_combos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63403468",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in all_words:\n",
    "    all_word_combos.extend(bpe_breaker(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212501ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11688"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_combos = set(sorted(all_word_combos))\n",
    "len(all_word_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b33df862",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:index for index,token in enumerate(all_word_combos) if token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7d032f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bpe_tokenizer:\n",
    "    def __init__(self):\n",
    "        self.s2i = vocab\n",
    "        self.i2s = {index:token for token,index in vocab.items()}\n",
    "    def bpe_breaker(self, st=''):\n",
    "        subsets = []\n",
    "        for i in range(len(st)):\n",
    "            for j in range(len(st),0,-1):\n",
    "                if st[i:j]:\n",
    "                    subsets.append(st[i:j])\n",
    "        return subsets\n",
    "    def encode(self, input_text):\n",
    "        ids = []\n",
    "        input_text+=\"<|EOT|>\"\n",
    "        inp = re.split(r'([,.;?_!\"()\\']|--|\\s)',input_text)\n",
    "        for word in inp:\n",
    "            while word != \"\":\n",
    "                # print(f\"--->{word}\")\n",
    "                try:\n",
    "                    if self.s2i[word]:\n",
    "                        ids.append(self.s2i[word])\n",
    "                        break\n",
    "                except:\n",
    "                    for part in self.bpe_breaker(word):\n",
    "                        try:\n",
    "                            if self.s2i[part]:\n",
    "                                ids.append(self.s2i[part])\n",
    "                                word = word[:word.index(part)]+word[word.index(part)+len(part):]\n",
    "                                break\n",
    "                        except Exception as e:\n",
    "                            print(f\" -- ERROR --> {e} \")\n",
    "                            pass\n",
    "        return ids\n",
    "    def decode(self, ids):\n",
    "        for i in ids:\n",
    "            text = \"\".join([self.i2s[i] for i in ids])\n",
    "            text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text).replace(\"' \",\"'\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01ad485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- ERROR --> 'asbsaggav' \n",
      " -- ERROR --> 'asbsagga' \n",
      " -- ERROR --> 'asbsagg' \n",
      " -- ERROR --> 'asbsag' \n",
      " -- ERROR --> 'asbsa' \n",
      " -- ERROR --> 'asbs' \n",
      " -- ERROR --> 'asb' \n",
      " -- ERROR --> 'bsaggav' \n",
      " -- ERROR --> 'bsagga' \n",
      " -- ERROR --> 'bsagg' \n",
      " -- ERROR --> 'bsag' \n",
      " -- ERROR --> 'bsa' \n",
      " -- ERROR --> 'aggav' \n",
      " -- ERROR --> 'agga' \n",
      "35\n",
      "His asbsaggav confident eyes grew dim, and his cheeks paled a little under their h.\n",
      "His asbsaggav confident eyes grew dim, and his cheeks paled a little under their h.<|EOT|>\n"
     ]
    }
   ],
   "source": [
    "string_ = \"His asbsaggav confident eyes grew dim, and his cheeks paled a little under their h.\"\n",
    "bpe = bpe_tokenizer()\n",
    "encoded_tokens = bpe.encode(string_)\n",
    "decoded_ids = bpe.decode(encoded_tokens)\n",
    "\n",
    "print(len(encoded_tokens))\n",
    "print(string_)\n",
    "print(decoded_ids)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
